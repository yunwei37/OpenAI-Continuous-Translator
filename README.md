# ğŸŒ OpenAI-Continuous-Translator

[![Continuous Translation test](https://github.com/yunwei37/OpenAI-Continuous-Translator/actions/workflows/translation.yml/badge.svg)](https://github.com/yunwei37/OpenAI-Continuous-Translator/actions/workflows/translation.yml)
[![Integration Test](https://github.com/yunwei37/OpenAI-Continuous-Translator/actions/workflows/integration.yml/badge.svg)](https://github.com/yunwei37/OpenAI-Continuous-Translator/actions/workflows/integration.yml)

OpenAI-Continuous-Translator is an open-source project that enables continuous translation (Or internationalization, i18n) in multiple formats and languages, including code comments, using OpenAI's `ChatGPT/GPT4` API in your `GitHub Action`.

Support file format:

- Markdown
- rst
- txt
- HTML
- jupyter notebook
- cpp/c/python/js (code comments)
- others are comming soon...

## ğŸ”§ Setup the github action

### Repository Settings

#### 1. Settings > Actions > General

- Enable `Read and write permissions`
- Enable `Allow GitHub Actions to create and approve pull requests`
![permissions](https://user-images.githubusercontent.com/69892552/228692074-d8d009a8-9272-4023-97b1-3cbc637d5d84.jpg)

#### 2. Settings > Secrets and variables > Actions

- Set API key(`OPENAI_API_KEY`) to secrets
![secrets](https://user-images.githubusercontent.com/69892552/228692421-22d7db33-4e32-4f28-b166-45b4d3ce2b11.jpg)

### GitHub Actions Workflow Settings

#### Required

- Provide the OPENAI_API_KEY as apiKey.
- Set `on` to trigger when a comment is created (`types: [ created ]`).
- Checkout in advance(`actions/checkout@v3`).

You can translate your repo with Github Actions:

1. Add the following to your github action:

  ```yml
      - uses: actions/checkout@v3
      - uses: yunwei37/OpenAI-Continuous-Translator@master
        with:
            git_repo_url: https://github.com/yourname/reponame
            api_key: ${{ secrets.OPENAI_API_KEY }}
  ```

  The `git_repo_url` does not always need to be the current repo. You can either make a mirror repo from the original one, or you internationalize the original repo.

You can add and commit the result:

```yml
      - name: Add & Commit
        uses: EndBug/add-and-commit@v9.1.1
```

And use [create-pull-request](https://github.com/peter-evans/create-pull-request) to create a PR for your repo:
```yml
    - name: Create Pull Request
      uses: peter-evans/create-pull-request@v4
```

### Example

Here is a complete example:

```yml
name: Continuous Translation

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 1' # At 00:00 on Monday

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: yunwei37/OpenAI-Continuous-Translator@master
      with:
          git_repo_url: https://github.com/radi-cho/awesome-gpt4
          api_key: ${{ secrets.OPENAI_API_KEY }}
    - name: Add & Commit
      uses: EndBug/add-and-commit@v9.1.1
    - name: Create Pull Request
      uses: peter-evans/create-pull-request@v4
```

The translated repo example maybe:

- https://github.com/yunwei37/Prompt-Engineering-Guide-zh-CN
- https://github.com/yunwei37/awesome-gpt4-zh-CN

The complete workflow is roughly as follows:

1. Spend two minutes configuring the corresponding API key and desired settings in the CI, as well as GitHub permissions.
2. GitHub Actions can periodically check the upstream repository for new changes, and if there are any, it will pull down the corresponding change and translate it.
3. The action will automatically submit the translated changes as a pull request in the current repository, which will be reviewed and proofread by humans before being merged.

## Features

For the translation result of GPT, please refer to [Is-ChatGPT-A-Good-Translator](https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator).

- Translation of multiple file formats, including HTML, rst, txt, and Markdown...

  For example, a Markdown file:

  ```markdown
  - **æç¤ºå·¥ç¨‹æŠ€æœ¯**:
  - [ä¸€ä¸ªæç¤ºæ¨¡å¼ç›®å½•ï¼Œå¢å¼º ChatGPT çš„æç¤ºå·¥ç¨‹](https://arxiv.org/abs/2302.11382) [2023] (Arxiv)
  - [è®©ç¡¬æç¤ºå®¹æ˜“ï¼šåŸºäºæ¢¯åº¦çš„ç¦»æ•£ä¼˜åŒ–æ–¹æ³•æ¥è¿›è¡Œæç¤ºè°ƒæ•´å’Œå‘ç°](https://arxiv.org/abs/2302.03668) [2023] (Arxiv)ã€‚- [åˆæˆæç¤ºï¼šä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ€è·¯æ¼”ç¤º](https://arxiv.org/abs/2302.00618) [2023] (Arxiv)
  - [æ¸è¿›æç¤ºï¼šç”¨äºè¯­è¨€æ¨¡å‹çš„è¿ç»­å­¦ä¹ ](https://arxiv.org/abs/2301.12314) [2023] (Arxiv)
  - [æ‰¹é‡æç¤ºï¼šä½¿ç”¨ LLM API è¿›è¡Œé«˜æ•ˆæ¨ç†](https://arxiv.org/abs/2301.08721) [2023] (Arxiv)
  - [è¿ç»­æç¤ºç”¨äºè§£ç­”å¤æ‚é—®é¢˜](https://arxiv.org/abs/2212.04092) [2022] (Arxiv)
  - [ç»“æ„åŒ–æç¤ºï¼šå°†ä¸Šä¸‹æ–‡å­¦ä¹ æ‰©å±•åˆ° 1,000 ä¸ªç¤ºä¾‹](https://arxiv.org/abs/2212.06713) [2022] (Arxiv)
  - [å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯äººç±»çº§çš„æç¤ºå·¥ç¨‹å¸ˆ](https://arxiv.org/abs/2211.01910) [2022] (Arxiv)
  - [é—®æˆ‘ï¼šä¸€ä¸ªä¸ºæç¤ºè¯­è¨€æ¨¡å‹è®¾è®¡çš„ç®€å•ç­–ç•¥](https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for) [2022] (Arxiv)
  - [æç¤º GPT-3 æˆä¸ºå¯é çš„æ¨¡å‹](https://arxiv.org/abs/2210.09150) [2022](Arxiv)
  - [åˆ†è§£æç¤ºï¼šä¸€ç§è§£å†³å¤æ‚ä»»åŠ¡çš„æ¨¡å—åŒ–æ–¹æ³•](https://arxiv.org/abs/2210.02406) [2022] (Arxiv)
  ```

  is translated from English to Chinese:

  ```markdown
  - **Prompt Engineering Techniques**:
  - [A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://arxiv.org/abs/2302.11382) [2023] (Arxiv)
  - [Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery](https://arxiv.org/abs/2302.03668) [2023] (Arxiv)
  - [Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models](https://arxiv.org/abs/2302.00618) [2023] (Arxiv) 
  - [Progressive Prompts: Continual Learning for Language Models](https://arxiv.org/abs/2301.12314) [2023] (Arxiv) 
  - [Batch Prompting: Efficient Inference with LLM APIs](https://arxiv.org/abs/2301.08721) [2023] (Arxiv)
  - [Successive Prompting for Decompleting Complex Questions](https://arxiv.org/abs/2212.04092) [2022] (Arxiv) 
  - [Structured Prompting: Scaling In-Context Learning to 1,000 Examples](https://arxiv.org/abs/2212.06713) [2022] (Arxiv) 
  - [Large Language Models Are Human-Level Prompt Engineers](https://arxiv.org/abs/2211.01910) [2022] (Arxiv) 
  - [Ask Me Anything: A simple strategy for prompting language models](https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for) [2022] (Arxiv) 
  - [Prompting GPT-3 To Be Reliable](https://arxiv.org/abs/2210.09150) [2022](Arxiv) 
  - [Decomposed Prompting: A Modular Approach for Solving Complex Tasks](https://arxiv.org/abs/2210.02406) [2022] (Arxiv) 
  ```

- Translation of code comments in multiple languages, including Python, Java, and JavaScript...

  For example, a Linux kernel code comment:

  ```c
    /* MEM points to BPF ring buffer reservation. */
    MEM_RINGBUF		= BIT(2 + BPF_BASE_TYPE_BITS),

    /* MEM is in user address space. */
    MEM_USER		= BIT(3 + BPF_BASE_TYPE_BITS),

    /* MEM is a percpu memory. MEM_PERCPU tags PTR_TO_BTF_ID. When tagged
    * with MEM_PERCPU, PTR_TO_BTF_ID _cannot_ be directly accessed. In
    * order to drop this tag, it must be passed into bpf_per_cpu_ptr()
    * or bpf_this_cpu_ptr(), which will return the pointer corresponding
    * to the specified cpu.
    */
    MEM_PERCPU		= BIT(4 + BPF_BASE_TYPE_BITS),
  ```

  will be translated into Chinese:

  ```c
  /* MEM æŒ‡å‘ BPF ç¯å½¢ç¼“å†²åŒºé¢„ç•™ã€‚*/
  MEM_RINGBUF		= BIT(2 + BPF_BASE_TYPE_BITS),

  /* MEM åœ¨ç”¨æˆ·åœ°å€ç©ºé—´ä¸­ã€‚ */
  MEM_USER		= BIT(3 + BPF_BASE_TYPE_BITS),

  /* MEM æ˜¯ percpu å†…å­˜ã€‚MEM_PERCPU æ ‡è®° PTR_TO_BTF_IDã€‚
  * è¢«æ ‡è®°ä¸º MEM_PERCPU çš„ PTR_TO_BTF_ID ä¸èƒ½ç›´æ¥è®¿é—®ã€‚
  * ä¸ºäº†å»é™¤æ­¤æ ‡è®°ï¼Œå¿…é¡»å°†å…¶ä¼ é€’åˆ° bpf_per_cpu_ptr() æˆ– bpf_this_cpu_ptr()ï¼Œ
  * è¿™å°†è¿”å›ä¸æŒ‡å®š cpu ç›¸å¯¹åº”çš„æŒ‡é’ˆã€‚
  */
  MEM_PERCPU		= BIT(4 + BPF_BASE_TYPE_BITS),
  ```

- Automatic detection of changes to Git repositories
- Configurable options, such as Git repository URL, source and target languages, and API key

  ```yml
  inputs:
    git_repo_url:
      description: "The git repo url to clone and translate"
    api_key:
      description: "The OpenAI api key to use for translation"
    source_language:
      description: "The source language to translate from. The default is English"
    target_language:
      description: "The target language to translate to. The default is Chinese"
    additional_prompt: 
      description: "Additional prompt to improve performance."
    i18n_surfix:
      description: "The i18n surfix to add to the translated file. The default is empty, so the translated file will overwrite the original file."
    file_types:
      description: "The file types to translate. The default is all file types supported"
    file_path_filter:
      description: "The file path filter to translate. The default is all files"
  ```

- Detailed logging to track translation progress and debug issues

## What is Continuous Translation?

Continuous translation is the practice of automating the translation of new content as it is created, allowing for seamless communication across different languages and cultures. By integrating with version control systems like Git, continuous translation ensures that translations are always up-to-date with the latest content, reducing the time and effort required for manual translation.

## Getting Started

### Run with docker

```shell
docker run -e INPUT_GIT_REPO_URL="https://github.com/yourname/reponame" INPUT_API_KEY="your_api_key" -v /path/to/your/repo:/app yunwei37/openai-continuous-translator:latest
```

### Run with python

To use OpenAI-Continuous-Translator, simply follow these steps:

1. Clone this repository to your local machine
2. Set up your OpenAI API key and Git repository URL in the env 
3. Install the required dependencies using `pip install -r requirements.txt`
4. Run the program using `python main.py`

OpenAI-Continuous-Translator will automatically detect changes to your Git repository and translate the new content into your desired language.

## Contributing

We welcome contributions from anyone! To contribute to OpenAI-Continuous-Translator, simply fork this repository, make your changes, and submit a pull request.

## License

OpenAI-Continuous-Translator is licensed under the MIT License. See the `LICENSE` file for more information.
